{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNXWpH9tGLWsdXyzByraiBl"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Intro\n",
        "Using code for the 33-60 age group in the colorectal\n",
        "cancer dataset as a sample. Age was encoded as follows:\n",
        "\n",
        "*   33-60: 'g_age_3grp1 = 1'\n",
        "*   61-72: 'g_age_3grp2 = 1'\n",
        "*   73+: 'g_age_3grp3 = 1'"
      ],
      "metadata": {
        "id": "F_Iqvlgdsq5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training on All Groups and Testing on an Individual Group"
      ],
      "metadata": {
        "id": "3TSwlcESIN0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate, train_test_split, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize lists to store results\n",
        "Accur_mean = []\n",
        "prec_mean = []\n",
        "rec_mean = []\n",
        "f1_mean = []\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(loadpath) #Currently placeholder\n",
        "df = df.set_index('Sample')\n",
        "print(df.head())\n",
        "\n",
        "# Prepare the features and labels\n",
        "X = df.drop('outcome', axis=1)  # Features\n",
        "X = X.fillna(method='ffill')  # Forward fill to handle NaN values\n",
        "y = df.outcome  # Labels\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
        "cv = KFold(n_splits=10, random_state=None, shuffle=True)\n",
        "\n",
        "# Function to run the model evaluation and return metrics\n",
        "def run_model_evaluation(model, X_train, y_train, X_test, y_test, group_column, group_value):\n",
        "    # Combine X_test and y_test\n",
        "    Comb = pd.concat([X_test, y_test], axis=1)\n",
        "    Combine = Comb[Comb[group_column] == group_value]  # Filter by group column and value\n",
        "    X_group = Combine.drop('outcome', axis=1).fillna(method='ffill')  # Handle missing data\n",
        "    y_group = Combine['outcome']\n",
        "\n",
        "    # Reset the metrics for each iteration\n",
        "    Accur_mean = []\n",
        "    prec_mean = []\n",
        "    rec_mean = []\n",
        "    f1_mean = []\n",
        "\n",
        "    # Loop through the specified number of iterations\n",
        "    for i in range(20):\n",
        "        # Train the model on the training data\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate the model using cross-validation\n",
        "        scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
        "        scores = cross_validate(model, X_group, y_group, scoring=scoring, cv=cv)\n",
        "\n",
        "        # Append the results\n",
        "        Accur_mean.append(scores['test_accuracy'].mean())\n",
        "        prec_mean.append(scores['test_precision_macro'].mean())\n",
        "        rec_mean.append(scores['test_recall_macro'].mean())\n",
        "        f1_mean.append(scores['test_f1_macro'].mean())\n",
        "\n",
        "    # Create a DataFrame to store the results\n",
        "    Accuracy = pd.DataFrame({\n",
        "        'Accuracy': Accur_mean,\n",
        "        'Precision': prec_mean,\n",
        "        'Recall': rec_mean,\n",
        "        'F1': f1_mean\n",
        "    })\n",
        "\n",
        "    # Calculate average and standard deviation\n",
        "    avg = Accuracy.mean()\n",
        "    std = Accuracy.std()\n",
        "\n",
        "    # Combine the results\n",
        "    Accuracy = pd.concat([Accuracy, avg.to_frame().T, std.to_frame().T])\n",
        "\n",
        "    return Accuracy"
      ],
      "metadata": {
        "id": "4CmyyBRhdLZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "r-BliVCtIWAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tuning the Model"
      ],
      "metadata": {
        "id": "QIGINNIbIaRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load and prepare data\n",
        "df = pd.read_csv('your_data.csv')  # Placeholder path\n",
        "df_i = df.set_index('Sample')\n",
        "\n",
        "X = df_i.drop(['outcome'], axis=1)\n",
        "y = df_i['outcome']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "# Storing results\n",
        "Accur = []\n",
        "Estimator = []\n",
        "Sample_split = []\n",
        "\n",
        "# Grid search over hyperparameters\n",
        "def run_tuning():\n",
        "    accuracies = []\n",
        "    estimators = []\n",
        "    sample_splits = []\n",
        "\n",
        "    for min_split in range(2, 14, 3):\n",
        "        for n_est in range(5, 150, 5):\n",
        "            model = RandomForestClassifier(bootstrap=True, class_weight=None,\n",
        "                criterion='gini', max_depth=None, max_features='sqrt',\n",
        "                max_leaf_nodes=None, min_impurity_decrease=0.0, min_samples_leaf=1,\n",
        "                min_samples_split=min_split, min_weight_fraction_leaf=0.0,\n",
        "                n_estimators=n_est, n_jobs=-1, oob_score=False, random_state=None,\n",
        "                verbose=0, warm_start=False)\n",
        "\n",
        "            scores = cross_val_score(model, X, y, cv=10)\n",
        "            accuracies.append(scores.mean())\n",
        "            estimators.append(n_est)\n",
        "            sample_splits.append(min_split)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'Estimator': estimators,\n",
        "        'Sample Split': sample_splits,\n",
        "        'Accuracy': accuracies\n",
        "    })\n",
        "\n",
        "# Run tuning 3 times independently\n",
        "results_run0 = run_tuning()\n",
        "results_run1 = run_tuning()\n",
        "results_run2 = run_tuning()\n",
        "\n",
        "# Merge results\n",
        "merged = results_run0.merge(results_run1, on=['Estimator', 'Sample Split'], suffixes=('_0', '_1'))\n",
        "merged = merged.merge(results_run2, on=['Estimator', 'Sample Split'])\n",
        "merged.rename(columns={'Accuracy': 'Accuracy_2'}, inplace=True)\n",
        "\n",
        "# Average accuracy across runs\n",
        "merged['Avg Accuracy'] = merged[['Accuracy_0', 'Accuracy_1', 'Accuracy_2']].mean(axis=1)\n",
        "\n",
        "# Identify best parameter combination\n",
        "best = merged.sort_values('Avg Accuracy', ascending=False).head(1)\n",
        "final_estimator = best['Estimator'].values[0]\n",
        "final_split = best['Sample Split'].values[0]\n",
        "\n",
        "print(\"\\nBest hyperparameters found:\")\n",
        "print(f\"n_estimators = {final_estimator}\")\n",
        "print(f\"min_samples_split = {final_split}\")\n",
        "print(best)"
      ],
      "metadata": {
        "id": "FCQXHh55JPi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training/Testing the Model"
      ],
      "metadata": {
        "id": "OJiMlMesKQyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing RF model and inputting hyperparameters found\n",
        "rfc=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "              max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
        "              min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=final_split,\n",
        "              min_weight_fraction_leaf=0.0, n_estimators=final_estimator, n_jobs=-1,\n",
        "              oob_score=False, random_state=None, verbose=0,\n",
        "              warm_start=False)"
      ],
      "metadata": {
        "id": "XoVp5ogCdvNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_column_rf = 'g_age_3grp1'  # Feature to filter by\n",
        "group_value_rf = 1  # Value for feature\n",
        "rfc_accuracy = run_model_evaluation(rfc, X_train, y_train, X_test, y_test, group_column_rf, group_value_rf)\n",
        "print(\"Random Forest Performance:\")\n",
        "print(rfc_accuracy)"
      ],
      "metadata": {
        "id": "yxsm7Jp1drYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multinomial Logistic Regression"
      ],
      "metadata": {
        "id": "3-A1_s49LyfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing MLogit\n",
        "mlog = LogisticRegression(random_state=None, multi_class='multinomial',\n",
        "                        penalty='none', solver='newton-cg').fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "xhQxiZfwecnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_column_mlog = 'g_age_3grp1'  # Feature to filter by\n",
        "group_value_mlog = 1  # Value for feature\n",
        "mlog_accuracy = run_model_evaluation(mlog, X_train, y_train, X_test, y_test, group_column_mlog, group_value_mlog)\n",
        "print(\"Logistic Regression Performance:\")\n",
        "print(mlog_accuracy)"
      ],
      "metadata": {
        "id": "qk5-d94hemkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Linear Support Vector Classifier"
      ],
      "metadata": {
        "id": "QDHOybg-qOOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing Linear SVC\n",
        "svc = svm.LinearSVC(penalty='l2', loss='squared_hinge', dual=True,\n",
        "                    tol=0.0001, C=1.0, multi_class='ovr', fit_intercept=True,\n",
        "                    intercept_scaling=1, class_weight=None, verbose=0,\n",
        "                    random_state=None, max_iter=1000).fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "V8Hheb-Se0HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_column_svc = 'g_age_3grp1'  # Feature to filter by\n",
        "group_value_svc = 1  # Value for feature\n",
        "svc_accuracy = run_model_evaluation(svc, X_train, y_train, X_test, y_test, group_column_svc, group_value_svc)\n",
        "print(\"Linear SVC Performance:\")\n",
        "print(svc_accuracy)"
      ],
      "metadata": {
        "id": "_ogntP5xyRZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Discriminant Analysis"
      ],
      "metadata": {
        "id": "_2UeQ1WhVpBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing LDA\n",
        "lda = LinearDiscriminantAnalysis(solver='svd', shrinkage=None, priors=None,\n",
        "                                 n_components=None, store_covariance=False,\n",
        "                                 tol=0.0001, covariance_estimator=None).fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "EgKbKMbOyetf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_column_lda = 'g_age_3grp1'  # Feature to filter by\n",
        "group_value_lda = 1  # Value for feature\n",
        "lda_accuracy = run_model_evaluation(lda, X_train, y_train, X_test, y_test, group_column_lda, group_value_lda)\n",
        "print(\"LDA Performance:\")\n",
        "print(lda_accuracy)"
      ],
      "metadata": {
        "id": "TJjMeHm4yfDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multilayer Perceptron"
      ],
      "metadata": {
        "id": "GHxvRnZOVsev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing MLP\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.0001,\n",
        "                    learning_rate='constant', learning_rate_init=0.001,max_iter=200,\n",
        "                    random_state=None, tol=0.0001, verbose=False, warm_start=False,\n",
        "                    validation_fraction=0.1, max_fun=15000).fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "GCFNcipAywOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_column_mlp = 'g_age_3grp1'  # Feature to filter by\n",
        "group_value_mlp = 1  # Value for feature\n",
        "mlp_accuracy = run_model_evaluation(mlp, X_train, y_train, X_test, y_test, group_column_mlp, group_value_mlp)\n",
        "print(\"MLP Performance:\")\n",
        "print(mlp_accuracy)"
      ],
      "metadata": {
        "id": "4Ich-Dlsy1UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training on All Groups and Testing on a Merged Group\n",
        "Using 'g_age_3grp1' = 0 as indication that patient belongs to either group 2 or group 3. This then creates Group 2+3"
      ],
      "metadata": {
        "id": "I6Mue0w3cgR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample in Random Forest"
      ],
      "metadata": {
        "id": "-9EqkdWLzPP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "group_column_rf_merge = 'g_age_3grp1'  # Feature to filter by\n",
        "group_value_rf_merge = 0  # Value for feature\n",
        "rfc_accuracy_merge = run_model_evaluation(rfc, X_train, y_train, X_test, y_test,\n",
        "                                          group_column_rf_merge, group_value_rf_merge)\n",
        "print(\"Random Forest Performance:\")\n",
        "print(rfc_accuracy_merge)"
      ],
      "metadata": {
        "id": "KjfUbMtCzOqb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}